import argparse

import pandas as pd

import src.common.storage.collection_and_field_names as names
import src.loaders.common.loader_common_names as loader_common_names
import src.loaders.common.loader_helper as loader_helper

"""
PROTOTYPE - Prepare GTDB genome statistics data in JSON format for arango import.

This script parses genome features from the GTDB metadata files. Those features should be put into the global variable 
SELECTED_FEATURES.

NOTE: The Document Key ("_key") in Arango DB is generated by applying a hash function to a string consisting of the 
kbase_collection, load_version, and genome id parsed from the accession field from the GTDB metadata file. 
(e.g. GTDB_r207.kbase.1_GCA_000016605.1, GTDB_r207.kbase.1_GCA_000169995.1)

usage: gtdb_genome_attribs_loader.py [-h] --load_ver LOAD_VER [--kbase_collection KBASE_COLLECTION]
                                     [--root_dir ROOT_DIR]
                                     load_files [load_files ...]

options:
  -h, --help            show this help message and exit

required named arguments:
  load_files            GTDB genome metadata files (e.g. ar53_metadata_r207.tsv)
  --load_ver LOAD_VER   KBase load version. (e.g. r207.kbase.1)

optional arguments:
  --kbase_collection KBASE_COLLECTION
                        kbase collection identifier name (default: loader_common_names.DEFAULT_KBASE_COLL_NAME)
  --root_dir ROOT_DIR   Root directory for the collections project. (default:
                        /global/cfs/cdirs/kbase/collections)
  --file_group FILE_GROUP
                        File group permission for created data files. Default is kbase. Set
                        to no:group to keep the file group unchanged.

e.g. gtdb_genome_attribs_loader.py bac120_metadata_r207.tsv ar53_metadata_r207.tsv --load_version r207.kbase.1
     gtdb_genome_attribs_loader.py bac120_metadata_r207.tsv ar53_metadata_r207.tsv --load_version r207.kbase.1 --kbase_collection GTDB
"""

# Note that FLD_GENOME_ATTRIBS_GTDB_LINEAGE is required for some matchers to function.
# Since it's always part of the GTDB file we don't bother independently checking for its
# presence

# Taxonomy attribute name derived from GTDB metadata file
TAXA_ATTRI_NAME = 'gtdb_taxonomy'
# Map for updating generated document name
GENOME_ATTRI_MAPPING = {TAXA_ATTRI_NAME: names.FLD_GENOME_ATTRIBS_GTDB_LINEAGE}

"""
The following features will be extracted from the GTDB metadata file 
(e.g. ar122_metadata_r202.tsv and bac120_metadata_r202.tsv)
"""
SELECTED_FEATURES = {'accession', 'checkm_completeness', 'checkm_contamination', 'checkm_marker_count',
                     'checkm_marker_lineage', 'checkm_marker_set_count', 'contig_count', 'gc_count', 'gc_percentage',
                     'genome_size', TAXA_ATTRI_NAME, 'longest_contig', 'longest_scaffold',
                     'mean_contig_length',
                     'mean_scaffold_length', 'mimag_high_quality', 'mimag_low_quality', 'mimag_medium_quality',
                     'n50_contigs', 'n50_scaffolds', 'ncbi_assembly_level', 'ncbi_assembly_name', 'ncbi_bioproject',
                     'ncbi_biosample', 'ncbi_country', 'ncbi_date', 'ncbi_genbank_assembly_accession',
                     'ncbi_genome_category', 'ncbi_isolate', 'ncbi_isolation_source', 'ncbi_lat_lon',
                     'ncbi_organism_name',
                     'ncbi_seq_rel_date', 'ncbi_species_taxid', 'ncbi_strain_identifiers', 'ncbi_submitter',
                     'ncbi_taxid',
                     'ncbi_taxonomy_unfiltered', 'protein_count', 'scaffold_count', 'ssu_count', 'ssu_length',
                     'trna_aa_count', 'trna_count', 'trna_selenocysteine_count'}

# Copy the value of the following column to a new column FLD_KBASE_ID,
# which is the sort key for the genome attribute collection.
KBASE_GENOME_ID_COL = 'accession'


def _parse_from_metadata_file(load_files, exist_features, additional_features=None):
    """
    Fetches certain columns (combination of exist_features and additional_features) from GTDB metadata file
    and saves result as a pandas data from
    """

    if additional_features is None:
        additional_features = {}

    frames = [pd.read_csv(load_file, sep='\t', header=0, keep_default_na=False,
                          usecols=exist_features.union(additional_features)) for load_file in load_files]
    df = pd.concat(frames, ignore_index=True)

    return df


def _row_to_doc(row, kbase_collection, load_version):
    """
    Transforms row (from a dataframe) into ArangoDB collection document
    """
    # parse genome id
    genome_id = loader_helper.parse_genome_id(row.accession)
    doc = loader_helper.init_row_doc(kbase_collection, load_version, genome_id)

    doc.update(row.to_dict())

    # maps key specified in GENOME_ATTRI_MAPPING and uses original keys if no mapping is specified
    doc = {GENOME_ATTRI_MAPPING.get(k, k): v for k, v in doc.items()}

    return doc


def _df_to_docs(df, kbase_collection, load_version):
    """
    Convert a DataFrame into a list of documents that will be imported into the genome attributes collection.
    """

    # Create the FLD_KBASE_ID column by copying the KBASE_GENOME_ID_COL column
    loader_helper.copy_column(df, KBASE_GENOME_ID_COL, names.FLD_KBASE_ID)
    docs = df.apply(_row_to_doc, args=(kbase_collection, load_version), axis=1).to_list()

    return docs


def main():
    parser = argparse.ArgumentParser(
        description='PROTOTYPE - Prepare GTDB genome statistics data in JSON format for arango import.')
    required = parser.add_argument_group('required named arguments')
    optional = parser.add_argument_group('optional arguments')

    # Required positional argument
    required.add_argument('load_files', type=argparse.FileType('r'), nargs='+',
                          help='GTDB genome metadata files (e.g. ar53_metadata_r207.tsv)')

    # Required flag argument
    required.add_argument(f'--{loader_common_names.LOAD_VER_ARG_NAME}', required=True, type=str,
                          help=loader_common_names.LOAD_VER_DESCR)

    # Optional argument
    optional.add_argument(f'--{loader_common_names.KBASE_COLLECTION_ARG_NAME}', type=str,
                          default=loader_common_names.DEFAULT_KBASE_COLL_NAME,
                          help=loader_common_names.KBASE_COLLECTION_DESCR)
    optional.add_argument(
        f'--{loader_common_names.ROOT_DIR_ARG_NAME}',
        type=str,
        default=loader_common_names.ROOT_DIR,
        help=f'{loader_common_names.ROOT_DIR_DESCR} (default: {loader_common_names.ROOT_DIR})'
    )
    optional.add_argument(
        f'--{loader_common_names.DEFAULT_FILE_GROUP_ARG_NAME}',
        type=str,
        default=loader_common_names.DEFAULT_FILE_GROUP,
        help=loader_common_names.DEFAULT_FILE_GROUP_DESCR
    )

    args = parser.parse_args()
    load_files = args.load_files
    load_version = getattr(args, loader_common_names.LOAD_VER_ARG_NAME)
    kbase_collection = getattr(args, loader_common_names.KBASE_COLLECTION_ARG_NAME)
    file_group = getattr(args, loader_common_names.DEFAULT_FILE_GROUP_ARG_NAME)
    file_group = None if file_group == loader_common_names.KEEP_FILE_GROUP else file_group

    print('start parsing input files')
    df = _parse_from_metadata_file(load_files, SELECTED_FEATURES)
    docs = _df_to_docs(df, kbase_collection, load_version)

    docs, meta_doc = loader_helper.process_columnar_meta(docs,
                                                         kbase_collection,
                                                         load_version)
    env = loader_common_names.DEFAULT_ENV
    root_dir = getattr(args, loader_common_names.ROOT_DIR_ARG_NAME)

    attri_output = f'{kbase_collection}_{load_version}_{names.COLL_GENOME_ATTRIBS}.jsonl'
    loader_helper.create_import_files(root_dir, env, kbase_collection, load_version, attri_output, docs, file_group)

    meta_output = f'{kbase_collection}_{load_version}_{names.COLL_GENOME_ATTRIBS_META}.jsonl'
    loader_helper.create_import_files(root_dir, env, kbase_collection, load_version, meta_output, [meta_doc], file_group)


if __name__ == "__main__":
    main()
