import copy
import os
from pathlib import Path
from typing import Dict, List, Set

import jsonlines
import pandas as pd

from src.loaders.common import loader_common_names

# used as collection_and_field_names.FLD_KBASE_ID
TOOL_KBASE_ID = "kbase_id"
TOOL_GENOME_ATTRI_FILE = "genome_attribs.jsonl"


def create_jsonl_files(
        file_path: Path,
        docs: list) -> None:
    """
    create jsonl file from the list of documents

    :param file_path: the path to the jsonl file
    :param docs: the list of documents
    """
    print(f'Creating JSONLines import file: {file_path}')
    with jsonlines.open(file_path, mode='w') as writer:
        writer.write_all(docs)


def read_genome_attri_result(
        batch_result_dir: Path,
        tool_file_name: str,
        features: Set[str],
        genome_id_col: str,
        prefix: str = '') -> List[Dict[str, str]]:
    """
    process the output file generated by the tool (checkm2, gtdb-tk, etc) to create a format suitable for
    importing into ArangoDB

    :param batch_result_dir: the directory where the tool result files are stored
    :param tool_file_name: the name of the tool result file
    :param features: a list of features to be retrieved from the tool result file
    :param genome_id_col: the column name of the genome id in the tool result file
    :param prefix: the prefix to append to the genome id from the tool result file

    :return: a dictionary of genome attributes
    """

    # retrieve and process the genome metadata file
    metadata_file = os.path.join(batch_result_dir, loader_common_names.GENOME_METADATA_FILE)
    try:
        meta_df = pd.read_csv(metadata_file, sep='\t')
    except Exception as e:
        raise ValueError('Unable to retrieve the genome metadata file') from e
    tool_genome_map = dict(
        zip(meta_df[loader_common_names.META_TOOL_IDENTIFIER], meta_df[loader_common_names.META_DATA_ID]))

    tool_file = os.path.join(batch_result_dir, tool_file_name)
    docs = list()
    if os.path.exists(tool_file):
        df = _read_tsv_as_df(tool_file, features, genome_id_col=genome_id_col)
        docs = df.apply(_row_to_doc, args=(features, tool_genome_map,
                                           genome_id_col, prefix), axis=1).to_list()
        docs = [doc for doc in docs if doc]

    return docs


def _row_to_doc(row, features, tool_genome_map, genome_id_col, prefix):
    # Transforms a row from tool result file into ArangoDB collection document

    try:
        genome_id = tool_genome_map[row[genome_id_col]]
    except KeyError as e:
        raise ValueError('Unable to find genome ID') from e

    doc = _create_doc(row, genome_id, features, prefix)

    return doc


def _create_doc(row, genome_id, features, prefix):
    # Select specific columns and prepare them for import into Arango

    # NOTE: The selected column names will have a prefix added to them if pre_fix is not empty.

    # initialize the document with the genome_id
    doc = {
        TOOL_KBASE_ID: genome_id,
    }

    # distinguish the selected fields from the original metadata by adding a common prefix to their names
    if features:
        doc.update(row[list(features)].rename(lambda x: prefix + '_' + x if prefix else x).to_dict())
    else:
        doc.update(row.rename(lambda x: prefix + '_' + x if prefix else x).to_dict())

    return doc


def _read_tsv_as_df(file_path, features, genome_id_col=None):
    # Retrieve the desired fields from a TSV file and return the data in a dataframe

    selected_cols = copy.deepcopy(features) if features else None

    if selected_cols and genome_id_col:
        selected_cols.add(genome_id_col)

    df = pd.read_csv(file_path, sep='\t', keep_default_na=False, usecols=selected_cols)

    return df
